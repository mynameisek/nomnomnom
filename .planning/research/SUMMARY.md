# Project Research Summary

**Project:** NOM v1.2 — Dish Enrichment Intelligence Layer
**Domain:** Restaurant menu scanning / AI culinary intelligence — additive milestone on top of v1.1
**Researched:** 2026-02-28
**Confidence:** HIGH

## Executive Summary

NOM v1.2 adds a culinary intelligence layer to an already-shipping Next.js 16 + Supabase + OpenAI menu scanning app. The milestone introduces five capabilities: dish enrichment (cultural context, canonical names, ingredient summaries), AI Top 3 recommendations grounded to actual menu items, reverse semantic search across all scanned menus, dish images sourced from licensed APIs, and ES/IT translation support. The central architectural finding is that zero new npm packages are required — every feature is delivered through database schema additions, prompt engineering, one new environment variable (`UNSPLASH_ACCESS_KEY`), and new locale files. This is a low-risk, incremental milestone with a clear dependency chain.

The recommended approach centers on canonical name normalization as the keystone: every other feature (enrichment, image lookup, reverse search, cross-restaurant matching, community trust badge) depends on having a normalized, stable identifier per dish. Canonical names are generated by GPT-4o-mini at parse time and anchored by a seed table of ~100–200 common regional dishes for the Strasbourg market. Enrichment must be lazy and asynchronous — triggered post-scan via Next.js `after()`, exactly as Google Places enrichment already works in v1.1. Semantic reverse search uses Supabase pgvector (already available in the stack) with an HNSW index and an RPC function, avoiding any external vector database.

The critical risks are operational, not architectural. The top three dangers are: (1) enrichment blocking scan pipeline response time by being inserted synchronously — prevent by always using `after()`, (2) per-dish LLM calls multiplying cost linearly with menu size instead of batching all dishes in a single call, and (3) embedding model switching silently invalidating the entire search index — prevent by storing `embedding_model` alongside each vector from day one. All other pitfalls (image licensing, canonical name inconsistency, Top 3 hallucination) have clear, low-effort prevention strategies that must be baked into initial implementation, not retrofitted.

## Key Findings

### Recommended Stack

The v1.1 stack already contains every package needed for v1.2. The `ai` package (v6.0.99) exposes `embed` and `embedMany` for embedding generation. `@ai-sdk/openai` exposes `openai.embeddingModel('text-embedding-3-small')`. Supabase pgvector is available as an extension on the existing Supabase instance. `next-intl` supports any ISO 639-1 locale code. DeepL already supports ES/IT natively.

**Core technologies (new usage, not new packages):**
- `text-embedding-3-small` (OpenAI): dish and query embedding at 1536 dims, $0.02/1M tokens — negligible cost at dish scale; do not use `text-embedding-3-large` (5x storage cost, marginal quality gain for short dish names)
- `pgvector` (Supabase extension): semantic reverse search via HNSW index and `match_dishes()` RPC — no separate vector DB needed; HNSW preferred over IVFFlat for incrementally growing tables
- `GPT-4o-mini` (existing): batch enrichment (canonical name, cultural context, origin) — sufficient quality at 8–10x lower cost than GPT-4o for structured enrichment tasks
- Unsplash REST API (direct `fetch`, no npm package): licensed dish images via canonical name search — the `unsplash-js` npm package is archived and must not be used
- `next-intl` (existing): ES/IT locale files added to existing routing config — zero infrastructure change

**One new environment variable:** `UNSPLASH_ACCESS_KEY`. All other keys already exist.

**New database additions:** pgvector extension, `unaccent` extension, four new columns on `menu_items` (`canonical_name`, `cultural_context`, `enrichment_status`, `embedding vector(1536)`), HNSW index, partial index on pending enrichment status, and `match_dishes()` RPC function.

See `.planning/research/STACK.md` for complete schema SQL, AI SDK usage patterns, API call code, and version compatibility notes.

### Expected Features

Feature research confirms canonical name normalization as the architectural keystone — no other v1.2 feature can be built without it. All features except ES/IT translation depend on `canonical_name` as their key.

**Must have — v1.2.0 launch (P1):**
- Canonical name normalization — GPT-4o-mini batch call at parse time, seeded with ~100–200 regional dish anchors; unlocks everything else
- Dish enrichment on-demand — cultural explanation, origin, typical ingredients, how-to-eat; lazy LLM call on first tap, cached permanently in Supabase
- Dish images — Unsplash → Pexels → gradient+emoji fallback chain, cached in `image_url` + `image_credit` columns; attribution display is non-negotiable per API terms
- AI Top 3 — GPT-4o-mini call grounded to actual menu item UUIDs with Zod-validated structured output; 3x/day free gate via localStorage (no account required)
- Top 3 rationale display — `match_reason` + `diversity_note` + `clarity_score` per recommendation; the differentiator vs competitor "magic box" AI
- ES/IT translation — add locale codes to existing cascade; add `es`/`it` fields to GPT translation schema
- Community trust badge — increment `scan_count` per canonical dish; show badge at 3+ independent scans; extends v1.1 trust hierarchy (Menu / Inferred / Community)

**Should have — v1.2.x after validation (P2, requires 50+ canonical records):**
- Reverse search Tier 1 — fuzzy text match on canonical keys and variant aliases
- Reverse search Tier 2 — pgvector semantic similarity; activate at 100+ embeddings stored
- Reverse search UI — bottom sheet overlay, not a separate page (product Rule 8: scan = home, never feed)

**Defer to v2+:**
- "Find this dish near me" (requires accounts + location permissions)
- Cross-restaurant quality rankings (requires statistical significance from scan volume)
- Bulk enrichment backfill of historical menus (worthwhile at 500+ canonical dishes)
- API/RAG endpoint for canonical knowledge base (product vision Phase 4)

**Anti-features confirmed out of scope:**
- AI-generated photorealistic dish images — trust collapse when real dish arrives at table
- Full culinary encyclopedia per dish — 10-second attention window at restaurant table; link to TasteAtlas for depth-seekers
- Nutrition data / calories — unreliable for restaurant portions; dangerous for medical diets
- Real-time enrichment of all dishes at scan time — 30–80 sequential LLM calls = 15–40 seconds load + $0.30–$1.00 per scan
- User-submitted dish enrichment corrections — moderation overhead unjustifiable; "Flag as incorrect" button is the safe alternative

See `.planning/research/FEATURES.md` for full competitor analysis (TasteAtlas, Swiggy, Beli, Zomato, Yelp Menu Vision), user journey alignment, dependency graph, and full prioritization matrix.

### Architecture Approach

The v1.1 `after()` fire-and-forget pattern (used for Google Places enrichment) is the exact model to replicate for all async enrichment, embedding generation, and image fetching. The scan API route returns `{ menuId }` immediately after dish parsing; everything else runs in the background, storing results in dedicated columns. Progressive enhancement on the menu page polls `/api/enrich/status` every 5 seconds until enrichment completes, then updates DishCards without a page reload.

**Major components (new and modified):**
1. `lib/enrichment.ts` (new) — `enrichMenuItems()` orchestrator: marks items pending, processes in batches of 10, generates embeddings + canonical names + cultural context in parallel per batch, handles per-item errors without failing the whole menu
2. `lib/openai.ts` (modified) — add `generateEmbedding()` using the `openai` npm package directly (not AI SDK — embeddings API wrapper differs), `getTop3()` UUID-grounded with Zod-validated structured output, `enrichDish()` batching all dishes in one array-schema LLM call
3. `app/api/top3/route.ts` (new) — accepts `{ menuId, preference, lang }`, fetches actual menu items, calls `getTop3()`, validates every returned UUID against real items before responding
4. `app/api/search/route.ts` (new) — accepts `{ query }`, embeds via `generateEmbedding()`, calls `match_dishes()` Supabase RPC, returns ranked results with similarity scores
5. `app/api/enrich/status/route.ts` (new) — lightweight aggregate query returning enrichment completion state for client polling
6. `components/menu/Top3Panel.tsx` (new) — client component: preference input, localStorage rate gate, calls `/api/top3`, highlights DishCards by UUID
7. `components/search/ReverseSearchShell.tsx` (new) — functional replacement for the existing hardcoded landing demo; connects to `/api/search`
8. SQL migration — pgvector extension, 4 new columns on `menu_items`, HNSW index (cosine distance), partial index on pending enrichment, `match_dishes()` RPC function

**Note on architectural divergence:** ARCHITECTURE.md recommends deferring dish images to v1.3 (no clean per-dish image source identified at time of writing). STACK.md and FEATURES.md treat images as a P1 v1.2.0 feature using the Unsplash REST API. Resolution: include dish images in v1.2 but implement them last within the milestone, after core enrichment and Top 3 are stable and tested.

See `.planning/research/ARCHITECTURE.md` for complete file inventory (new vs modified), full SQL migration, all code patterns with implementation examples, data flow diagrams for all four flows, and an 8-step build order.

### Critical Pitfalls

1. **Enrichment blocking scan pipeline** — Any enrichment or embedding call inserted synchronously into `getOrParseMenu` or the scan route before returning `{ menuId }` adds 8–30s latency and risks Vercel function timeout. Prevention: exclusively use `after()` for all post-scan work. Warning sign: scan response time increases by more than 3s after adding enrichment.

2. **Per-dish LLM calls multiplying cost by N** — A 45-dish menu enriched with one LLM call per dish costs ~45x more than a single batched call. Prevention: batch all dishes in one GPT-4o-mini call returning an array schema. Use GPT-4o-mini (not GPT-4o) for enrichment. Warning sign: `for (const dish of dishes) { await enrichDish(dish) }` in enrichment code.

3. **Canonical name inconsistency for non-Western dishes** — LLMs produce non-deterministic canonical forms for Turkish, Arabic, and regional dishes without anchoring ("Mantı" → "Manti", "Turkish Dumplings", "Manti soup" across different scans). Prevention: seed table of 100–200 regional dish canonical forms included in the enrichment system prompt; post-processing normalization (lowercase, trim, collapse whitespace, remove trailing punctuation).

4. **Embedding model switching silently invalidates entire search index** — Switching from `text-embedding-3-small` to any other model after production embeddings exist causes reverse search to return meaningless results with no error thrown. Prevention: `embedding_model text NOT NULL` column in initial migration; commit to `text-embedding-3-small` for all of v1.2; full re-embed migration required before any model change.

5. **Top 3 hallucinating dishes not on the menu** — LLM recommends dishes from general food knowledge when the prompt does not strictly ground it to the available item list. Prevention: pass all dish UUIDs in the prompt, return only UUID references in Zod-validated structured output, validate every returned UUID server-side against actual `menu_items` before responding.

6. **Enrichment data discarded on cache TTL expiry re-parse** — The existing `translationCache` recycling logic in `cache.ts` was designed for translations only. On re-parse after TTL expiry, enrichment columns (`canonical_name`, `cultural_context`, `embedding`, `image_url`) are silently discarded and regenerated at full LLM cost. Prevention: extend `translationCache` recycling in `cache.ts` to include all enrichment fields, keyed by `name_original`.

7. **Dish image DMCA exposure** — Using Google Images scraping, SerpAPI (under active DMCA litigation as of Feb 2026), or hotlinked third-party URLs exposes the app to takedowns. Prevention: Wikimedia Commons, Unsplash, or Pexels APIs only; store `image_source` and `image_license` alongside every `image_url`; gradient+emoji is always the final fallback; never store a URL without provenance.

See `.planning/research/PITFALLS.md` for 10 full pitfall entries with warning signs, recovery strategies, UX pitfalls, integration gotchas, performance traps, and the "Looks Done But Isn't" verification checklist.

## Implications for Roadmap

The dependency chain is rigid: schema must precede code; canonical names must precede enrichment; enrichment must precede reverse search; reverse search must have populated data before it can be meaningful. This drives phase structure.

### Phase 1: Database Foundation + Types
**Rationale:** Everything else depends on schema. No feature can be coded until the migration is applied and TypeScript types reflect the new columns. Zero user-visible changes but unblocks all subsequent phases. HNSW index must be created in the initial migration, not retrofitted — this is the documented pitfall with pgvector (unlike IVFFlat, HNSW is safe to create before the table has data).
**Delivers:** pgvector + unaccent extensions, four new columns on `menu_items` (`canonical_name`, `cultural_context`, `enrichment_status`, `embedding vector(1536)`), HNSW index (cosine), partial index on pending enrichment status, `match_dishes()` RPC function, updated `MenuItem` TypeScript interface, `top3Schema` Zod schema, `embedding_model` column for model provenance tracking.
**Addresses:** Pitfall 4 (HNSW from day one), Pitfall 5 (embedding_model column from day one)
**Avoids:** IVFFlat index (wrong for dynamically growing table), adding schema columns piecemeal across phases
**Research flag:** No research needed. SQL is fully specified in ARCHITECTURE.md and STACK.md with ready-to-run migration.

### Phase 2: Canonical Names + Batch Enrichment (Async)
**Rationale:** Canonical naming is the keystone — the single dependency of every other v1.2 feature. Must ship and be stable before dish images, reverse search, or community badge. The batch approach (one LLM call per menu, not one per dish) prevents cost explosion. Enrichment recycling in `cache.ts` must be extended in this phase before any production enrichment fires.
**Delivers:** `lib/enrichment.ts` with `enrichMenuItems()`, `generateEmbedding()` and `enrichDish()` additions to `lib/openai.ts`, seed table for 100–200 regional dish canonical forms (content curation task, not code), `after()` integration in both scan routes (`/api/scan/url` and `/api/scan/photo`), `GET /api/enrich/status`, DishCard enrichment badge display, status polling in MenuShell, extended `translationCache` recycling for enrichment fields in `cache.ts`.
**Addresses:** Cultural explanation, origin, canonical name, community trust badge scaffolding (Features P1)
**Avoids:** Pitfall 1 (async only via `after()`), Pitfall 2 (one batch call per menu), Pitfall 3 (seed table + deterministic prompt), Pitfall 10 (extend recycling before production)
**Research flag:** Standard code patterns — `after()` pattern is proven in codebase; batch LLM schema fully specified in STACK.md and ARCHITECTURE.md. Content task: seed table requires culinary domain knowledge for the Strasbourg market (Turkish, Alsatian, North African dishes). Recommend building from first 5–10 production scans and locking before scale.

### Phase 3: AI Top 3 Recommendations
**Rationale:** Top 3 depends on enrichment for better rationale quality but can function with v1.1 dish data as a baseline. Build here to deliver immediate user-facing intelligence value before the more complex reverse search infrastructure. The rate-limit mechanism (localStorage UUID) must be implemented here to avoid the GDPR regression from v1.1 pitfalls.
**Delivers:** `getTop3()` in `lib/openai.ts`, `POST /api/top3` route, `Top3Panel.tsx` client component (preference input, localStorage rate gate, UUID-based DishCard highlighting), Top 3 rationale display (`match_reason`, `diversity_note`, `clarity_score`).
**Addresses:** AI Top 3 with criteria rationale (Features P1 differentiator), Top 3 rationale display
**Avoids:** Pitfall 7 (UUID-grounded prompt + server-side UUID validation before response), Pitfall 8 (localStorage UUID gate — not raw IP storage, not even hashed IP)
**Research flag:** Standard patterns — grounding strategy, Zod schema, and rate-limit approach fully specified in ARCHITECTURE.md and FEATURES.md. No phase research needed.

### Phase 4: Dish Images
**Rationale:** Dish images are a P1 feature. Placed after core enrichment and Top 3 because image lookup uses `canonical_name` as the search query (canonical names must be stable first) and because image infrastructure (Unsplash API key, attribution display, fallback chain) is independent and adds no blocking dependency for other features.
**Delivers:** `lib/images.ts` (server-only) with `fetchDishImage()`, background image fetch wired into `enrichMenuItems()` as an additional step, `image_url` + `image_credit` + `image_source` columns populated (schema added in Phase 1), attribution caption in DishCard, gradient+emoji fallback preserved and always active.
**Addresses:** Visual representation per dish (Features table stakes), Unsplash → Pexels → gradient+emoji fallback chain
**Avoids:** Pitfall 9 (Wikimedia/Unsplash/Pexels only; `image_source` stored per row; no hotlinking; no SerpAPI; no Google Images scraping); captions images as "Illustrative photo" to prevent trust collapse when real dish differs
**Research flag:** Low-risk. Unsplash REST API is fully documented in STACK.md. One attention point: Unsplash demo tier is 50 req/hr — initiate production approval application at phase start, not at launch.

### Phase 5: ES/IT Translation Support
**Rationale:** ES/IT is the lowest-risk, most-independent feature in the milestone. No new infrastructure — just locale JSON files and language codes added to the existing translation cascade. Placed here to avoid blocking core intelligence features while still shipping within v1.2.0. Fast win that completes the Strasbourg test market coverage.
**Delivers:** `messages/es.json`, `messages/it.json`, updated `next-intl` routing config with `'es'` and `'it'` locale codes, `es`/`it` fields added to GPT translation output schema.
**Addresses:** ES/IT translation parity (Features P1)
**Avoids:** Any modifications to the translation cascade itself — DeepL already supports both languages; no infrastructure change is needed or appropriate
**Research flag:** No research needed. Purely additive to existing, working code patterns.

### Phase 6: Reverse Search (Tier 1 + Tier 2)
**Rationale:** Reverse search is a P2 feature — it requires the canonical dish table to be meaningfully populated (50+ records) before it returns useful results. Build infrastructure in this phase but gate the promoted UI behind a data threshold. Tier 1 (fuzzy text match on canonical keys) ships first; Tier 2 (pgvector semantic similarity via `match_dishes()` RPC) activates when 100+ embeddings exist. The `match_threshold` must be calibrated against real Strasbourg menu data before shipping — it cannot be taken from documentation examples.
**Delivers:** `POST /api/search` route, `ReverseSearchShell.tsx` (functional replacement for hardcoded landing demo), `app/search/page.tsx`, `match_threshold` made configurable in admin dashboard (alongside existing model config), zero-result logging for threshold calibration data.
**Addresses:** Reverse search Tier 1 fuzzy match, Tier 2 semantic similarity (Features P2)
**Avoids:** Pitfall 4 (embeddings already generated in Phase 2 background task — no pipeline coupling), Pitfall 5 (model consistency enforced by `embedding_model` column), Pitfall 6 (threshold calibrated against 20–30 real-world queries, not hardcoded at 0.78)
**Research flag:** Moderate attention needed. The `match_threshold` value cannot be predetermined — requires empirical calibration with real Turkish/French/German/Alsatian dish embeddings. Plan a calibration step with representative test queries before promoting the UI.

### Phase Ordering Rationale

- **Schema-first is non-negotiable.** The HNSW index must exist before any embedding is written; the partial index on `enrichment_status` must exist before polling routes are built; `embedding_model` must be captured in the first migration, not added later when model consistency is already broken.
- **Canonical names before everything else.** Every other intelligence feature uses `canonical_name` as its key. Building any of them before canonical naming is stable creates technical debt that compounds across the entire milestone.
- **Async enrichment pattern before any user-visible enrichment UI.** If enrichment is wired synchronously even temporarily for testing, it will be left synchronous in production. The `after()` pattern must be the first and only implementation path — no "we'll make it async later."
- **Top 3 before reverse search.** Top 3 delivers immediate user value with a single menu in hand. Reverse search requires database accumulation (50+ canonical records) before it is meaningful. Shipping Top 3 first gives users something valuable while the knowledge graph grows.
- **Reverse search last, with data gate.** The `ReverseSearchShell` UI can be built at any point, but the feature should not be promoted until there is enough enriched data to return useful results. The existing landing page hardcoded demo can remain until the data threshold is met.
- **ES/IT placed at Phase 5** (after core intelligence, before reverse search) because it is independent of both and can be parallelized with Phase 4 if bandwidth allows.

### Research Flags

Phases needing calibration or content curation during execution:
- **Phase 2 (Canonical Names):** The seed table content (100–200 regional dish canonical forms for the Strasbourg market) must be curated before first production enrichment. This is a content task requiring culinary domain knowledge, not a code task. Recommend building programmatically from first 5–10 production scans, reviewing manually, then locking before enabling enrichment at scale.
- **Phase 6 (Reverse Search):** `match_threshold` requires empirical calibration against real dish embeddings from the Strasbourg restaurant market. No pre-determined safe value exists — the Supabase documentation example value (0.78) is explicitly data-dependent. Plan 20–30 real-world test queries across Turkish, French, Alsatian, and Italian dishes before promoting the UI.

Phases with well-documented patterns where phase research can be skipped:
- **Phase 1 (DB Schema):** SQL fully specified across STACK.md and ARCHITECTURE.md. No ambiguity.
- **Phase 3 (AI Top 3):** UUID-grounding pattern, Zod schema, and rate-limit approach all fully specified and verified.
- **Phase 4 (Dish Images):** Unsplash REST API fully documented; fallback chain prescribed; licensing approach clear.
- **Phase 5 (ES/IT):** Purely additive to existing, working patterns. No decisions to make.

## Confidence Assessment

| Area | Confidence | Notes |
|------|------------|-------|
| Stack | HIGH | All packages verified against official docs. Zero new npm packages confirmed. AI SDK v6 `embed` / `embedMany` / `openai.embeddingModel()` syntax verified via official docs. Unsplash archived package confirmed. HNSW vs IVFFlat recommendation verified against official Supabase docs. |
| Features | HIGH | Core enrichment patterns corroborated by Swiggy production data (50M dishes), TasteAtlas product analysis, and Supabase official docs. Canonical naming confidence is MEDIUM — LLM variability on non-Western dishes is documented (DoorDash engineering post-mortem, LLM normalization practitioner articles) but no published benchmark exists for the specific Strasbourg market cuisine mix. |
| Architecture | HIGH | Existing codebase read in full during research. `after()` pattern already proven for Google Places enrichment. pgvector RPC pattern verified against official Supabase docs (PostgREST cannot expose pgvector operators directly — RPC wrapping is required). Build order is dependency-driven with no architectural ambiguity. One divergence resolved: images included in v1.2 at Phase 4, implemented last. |
| Pitfalls | HIGH | All 10 pitfalls verified against official docs (OpenAI pricing, Supabase pgvector docs, OWASP LLM Top 10, Next.js `after()` docs). Image licensing risk verified against actual court filing (Google v. SerpAPI, December 2025) and ongoing case reporting (February 2026). Recovery strategies are concrete with time estimates. |

**Overall confidence: HIGH**

### Gaps to Address

- **Canonical name seed table content:** Requires culinary domain knowledge for the Strasbourg market — Turkish, Alsatian, North African, Italian dishes are the priority. This is not a code task. Recommended approach: build from the first 5–10 production scans, review manually, lock before enabling enrichment at scale. Approximately 100–200 entries needed for meaningful cross-restaurant matching.

- **Unsplash production approval:** Unsplash demo tier allows 50 req/hr. Production approval (5,000 req/hr) requires submitting an application per Unsplash guidelines. This must be initiated at Phase 4 start, not at launch — approval may take days.

- **Reverse search threshold calibration data:** The `match_threshold` for `match_dishes()` cannot be set correctly without real dish embeddings from the Strasbourg restaurant market. Plan a structured calibration step with 20–30 representative test queries across Turkish, French, Alsatian, and Italian dishes before Phase 6 UI is promoted. Add zero-result logging from day one to collect calibration data passively.

- **Vercel `after()` timeout ceiling for large menus:** Menus with 100+ dishes may exceed Vercel's extended function lifetime for `after()`. Implement a hard cap of 50 dishes per enrichment batch on first scan (remaining dishes enriched on subsequent requests) as a safety measure, not discovered in production. This cap should be in Phase 2 implementation, not added reactively.

## Sources

### Primary (HIGH confidence)
- [ai-sdk.dev/docs/ai-sdk-core/embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings) — `embed`, `embedMany` API, `openai.embeddingModel()` syntax in AI SDK v6
- [supabase.com/docs/guides/ai/hybrid-search](https://supabase.com/docs/guides/ai/hybrid-search) — pgvector + tsvector hybrid search, RRF fusion, HNSW index setup
- [supabase.com/docs/guides/database/extensions/pgvector](https://supabase.com/docs/guides/database/extensions/pgvector) — pgvector extension, vector column, `vector_cosine_ops`
- [supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes) — HNSW vs IVFFlat recommendation, `m` and `ef_construction` params; HNSW safe to create before table has data
- [platform.openai.com/docs/models/text-embedding-3-small](https://platform.openai.com/docs/models/text-embedding-3-small) — 1536 dimensions, $0.02/1M tokens
- [platform.openai.com/docs/models/gpt-4o-mini](https://platform.openai.com/docs/models/gpt-4o-mini) — $0.15/M input, $0.60/M output tokens
- [platform.openai.com/docs/guides/batch](https://platform.openai.com/docs/guides/batch) — 50% cost discount for async batch enrichment
- [unsplash.com/documentation](https://unsplash.com/documentation) — REST API endpoints, 50 demo / 5,000 production req/hr tiers, attribution requirements
- [github.com/unsplash/unsplash-js](https://github.com/unsplash/unsplash-js) — Confirmed archived/unmaintained; direct REST fetch is the correct approach
- [developers.deepl.com/docs/getting-started/supported-languages](https://developers.deepl.com/docs/getting-started/supported-languages) — ES/IT confirmed supported in existing cascade
- [next-intl.dev](https://next-intl.dev/) — Any ISO 639-1 locale code supported with no package changes
- [nextjs.org/docs/app/api-reference/functions/after](https://nextjs.org/docs/app/api-reference/functions/after) — `after()` extends serverless function lifetime post-response; the established v1.1 enrichment pattern
- [supabase.com/docs/guides/ai/semantic-search](https://supabase.com/docs/guides/ai/semantic-search) — RPC pattern for pgvector (PostgREST cannot expose pgvector operators directly)
- [genai.owasp.org/llmrisk/llm01-prompt-injection](https://genai.owasp.org/llmrisk/llm01-prompt-injection/) — LLM grounding and hallucination prevention

### Secondary (MEDIUM confidence)
- [Swiggy: Building Comprehensive LLM Platform for Food Delivery](https://www.zenml.io/llmops-database/building-a-comprehensive-llm-platform-for-food-delivery-services) — production enrichment with taxonomy at 50M dish scale
- [Swiggy Bytes: Semantic Embeddings for Food Search](https://bytes.swiggy.com/find-my-food-semantic-embeddings-for-food-search-using-siamese-networks-abb55be0b639) — embedding-based food search production data, corroborates pgvector approach
- [DoorDash: LLMs for food canonicalization](https://careersatdoordash.com/blog/doordash-llms-for-grocery-preferences-from-restaurant-orders/) — LLM variability on food tag canonicalization in production; corroborates Pitfall 3
- [Pinecone: OpenAI Embeddings v3](https://www.pinecone.io/learn/openai-embeddings-v3/) — 44% MIRACL multilingual benchmark for text-embedding-3-small; cross-language search capability
- [Google v. SerpAPI DMCA Lawsuit](https://ipwatchdog.com/2025/12/26/google-sues-serpapi-parasitic-scraping-circumvention-protection-measures/) — active litigation as of Feb 2026; SerpAPI is not a viable image source
- [Bing Search APIs Retirement](https://learn.microsoft.com/en-us/lifecycle/announcements/bing-search-api-retirement) — retired August 11, 2025; eliminates a previously common image sourcing approach
- [Datassential: Global Flavors Redefining Restaurant Trends 2025](https://datassential.com/resource/global-flavors-restaurants-growth-2025/) — 76% of consumers say detailed menu descriptions build confidence with unfamiliar dishes
- [Kinde: Freemium to Premium Billing Triggers](https://www.kinde.com/learn/billing/conversions/freemium-to-premium-converting-free-ai-tool-users-with-smart-billing-triggers/) — metered paywall UX patterns, 3x/day gate analysis

### Tertiary (LOW confidence — verify during implementation)
- [costgoat.com/pricing/openai-embeddings](https://costgoat.com/pricing/openai-embeddings) — batch pricing $0.01/1M tokens (third-party pricing calculator, not official)
- [Optimizing pgvector at Scale — Medium](https://medium.com/@dikhyantkrishnadalai/optimizing-vector-search-at-scale-lessons-from-pgvector-supabase-performance-tuning-ce4ada4ba2ed) — HNSW `ef_search` tuning guidance; consistent with official Supabase docs but practitioner-sourced
- [Microsoft AI Recommendation Poisoning Research — February 2026](https://www.microsoft.com/en-us/security/blog/2026/02/10/manipulating-ai-memory-for-profit-the-rise-of-ai-recommendation-poisoning/) — RAG poisoning patterns relevant to canonical dish knowledge graph in later phases

---
*Research completed: 2026-02-28*
*Ready for roadmap: yes*
