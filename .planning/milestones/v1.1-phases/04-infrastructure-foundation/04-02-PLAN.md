---
phase: 04-infrastructure-foundation
plan: 02
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - lib/openai.ts
  - lib/cache.ts
  - package.json
autonomous: true
requirements: [INFR-02, INFR-03]
user_setup:
  - service: openai
    why: "OpenAI API key needed for LLM menu parsing"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Dashboard -> API keys -> Create new secret key"

must_haves:
  truths:
    - "OpenAI wrapper accepts menu text and returns Zod-validated structured JSON (DishResponse array)"
    - "OpenAI wrapper reads the LLM model from admin_config (falling back to gpt-4o-mini default)"
    - "URL hash function produces deterministic SHA-256 hex from normalized URLs"
    - "Cache check queries Supabase by url_hash and respects expires_at timestamp"
    - "Cache miss triggers LLM call then stores result in Supabase via service role client"
    - "Cache hit returns stored data without any LLM call"
  artifacts:
    - path: "lib/openai.ts"
      provides: "Server-only OpenAI wrapper using AI SDK 6 generateText + Output.object()"
      contains: "parseDishesFromMenu"
    - path: "lib/cache.ts"
      provides: "URL hashing utility and cache-aware menu fetch orchestrator"
      contains: "hashUrl"
    - path: "package.json"
      provides: "AI SDK dependencies installed"
      contains: "@ai-sdk/openai"
  key_links:
    - from: "lib/openai.ts"
      to: "lib/types/llm.ts"
      via: "Import dishResponseSchema for structured output validation"
      pattern: "import.*dishResponseSchema.*from.*types/llm"
    - from: "lib/openai.ts"
      to: "@ai-sdk/openai"
      via: "OpenAI provider for AI SDK"
      pattern: "import.*openai.*from.*@ai-sdk/openai"
    - from: "lib/cache.ts"
      to: "lib/supabase-admin.ts"
      via: "Service role client for cache writes"
      pattern: "import.*supabaseAdmin"
    - from: "lib/cache.ts"
      to: "lib/supabase.ts"
      via: "Anon client for cache reads (preserves Next.js fetch cache)"
      pattern: "import.*supabase.*from.*supabase"
    - from: "lib/cache.ts"
      to: "lib/openai.ts"
      via: "LLM call on cache miss"
      pattern: "parseDishesFromMenu"
---

<objective>
Install AI SDK dependencies, create the server-only OpenAI wrapper with Zod-validated structured output, and build the URL hash cache layer that orchestrates cache-hit/miss logic.

Purpose: Wire the LLM integration and caching so that Phase 5 (Scan Pipeline) can call a single function to get parsed dishes — either from cache or from a fresh LLM call. This is the "brains" layer.

Output: Working OpenAI wrapper (lib/openai.ts), cache utilities (lib/cache.ts), and all npm dependencies installed.
</objective>

<execution_context>
@/Users/ekitcho/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ekitcho/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-infrastructure-foundation/04-RESEARCH.md
@.planning/phases/04-infrastructure-foundation/04-01-SUMMARY.md
@lib/supabase.ts
@lib/supabase-admin.ts
@lib/types/llm.ts
@lib/types/menu.ts
@lib/types/config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies and create OpenAI wrapper</name>
  <files>
    package.json
    lib/openai.ts
  </files>
  <action>
**Install dependencies:**
```bash
npm install ai @ai-sdk/openai zod@3.25.76 server-only
```

Pin zod at 3.25.76 exactly (not ^3) — Zod v4 breaks AI SDK's internal zod-to-json-schema conversion (research pitfall #1, GitHub issue #10014). After install, verify package.json shows `"zod": "3.25.76"` (not `"^3.25.76"`). If npm added the caret, manually edit package.json to remove it.

**Create `lib/openai.ts`:**

Server-only wrapper using AI SDK 6 pattern (`generateText` + `Output.object()`). NOT `generateObject` which is deprecated in AI SDK 6.

```typescript
import 'server-only';
import { generateText, Output, NoObjectGeneratedError } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';
import { dishResponseSchema } from './types/llm';
import type { DishResponse } from './types/llm';
```

**Function: `parseDishesFromMenu(menuText: string, model?: string)`**
- Default model: import `DEFAULT_LLM_MODEL` from `./types/config` as fallback
- The `model` parameter is passed in by the cache layer after reading admin_config
- Call `generateText` with:
  - `model: openai(model ?? DEFAULT_LLM_MODEL)`
  - `output: Output.object({ schema: z.object({ dishes: z.array(dishResponseSchema) }) })`
  - `maxRetries: 2`
  - `system` prompt: A detailed system prompt for multilingual menu parsing. The prompt should instruct the LLM to:
    1. Parse each dish from the raw menu text
    2. Provide the original name as it appears on the menu
    3. Translate name and description into FR, EN, TR, DE
    4. Identify EU 14 allergens (only list those with high confidence)
    5. Tag dietary categories (vegetarian, vegan, halal) when clear
    6. Set trust_signal to 'verified' for info directly from menu text, 'inferred' for LLM-inferred details
    7. Extract price if visible, null otherwise
  - `prompt`: the raw menuText
- Return `output` (which is `{ dishes: DishResponse[] }` — Zod-validated by AI SDK)
- Error handling: catch `NoObjectGeneratedError` specifically — log `error.text` (raw LLM output) and `error.cause` for debugging, then throw a descriptive error message

**Export:** `parseDishesFromMenu` as the only public export. The system prompt is a module-level constant (not exported).
  </action>
  <verify>
- `npm ls ai @ai-sdk/openai zod server-only` shows all 4 packages installed
- `grep '"zod"' package.json` shows exactly "3.25.76" (no caret)
- `grep 'server-only' lib/openai.ts` confirms server-only guard
- `grep 'generateText' lib/openai.ts` confirms using generateText (not generateObject)
- `grep 'Output.object' lib/openai.ts` confirms structured output pattern
- `grep 'NoObjectGeneratedError' lib/openai.ts` confirms proper error handling
- `npx tsc --noEmit` passes (no type errors)
  </verify>
  <done>
AI SDK 6 + OpenAI provider + Zod v3 + server-only installed. OpenAI wrapper at lib/openai.ts exports parseDishesFromMenu with Zod-validated structured output, proper error handling, and server-only guard. Zod pinned at 3.25.76.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create URL hash cache layer</name>
  <files>
    lib/cache.ts
  </files>
  <action>
Create `lib/cache.ts` — the cache orchestrator that ties together URL hashing, Supabase lookups, and the OpenAI wrapper.

**Import `'server-only'`** at the top — this module calls supabaseAdmin and openai, both server-only.

**Function: `hashUrl(url: string): string`**
- Normalize: `url.trim().toLowerCase()` — prevents cache misses from casing variations (research pitfall #3)
- Strip trailing slash if present
- Return `createHash('sha256').update(normalized).digest('hex')` from `node:crypto`

**Function: `getAdminConfig()`**
- Query `admin_config` via supabaseAdmin (service role — admin_config has no public RLS policy)
- `.from('admin_config').select('*').single()`
- Return the config row, or fall back to `{ llm_model: DEFAULT_LLM_MODEL, cache_ttl_hours: DEFAULT_CACHE_TTL_HOURS }` if query fails
- Import defaults from `./types/config`

**Function: `getOrParseMenu(url: string, sourceType: 'url' | 'photo' | 'qr', rawText: string)`**
This is the main entry point that Phase 5 will call. It orchestrates cache check → LLM call → cache store.

Steps:
1. `const urlHash = hashUrl(url)`
2. Read admin config: `const config = await getAdminConfig()`
3. **Cache check** — use anon supabase client (preserves Next.js fetch cache per v1.0 decision):
   ```typescript
   const { data: cached } = await supabase
     .from('menus')
     .select('*, menu_items(*)')
     .eq('url_hash', urlHash)
     .gt('expires_at', new Date().toISOString())
     .maybeSingle();
   ```
   If `cached` is not null → return it (cache HIT, no LLM call)

4. **Cache MISS** — call LLM:
   ```typescript
   const parsed = await parseDishesFromMenu(rawText, config.llm_model);
   ```

5. **Compute expiry:**
   ```typescript
   const expiresAt = new Date(Date.now() + config.cache_ttl_hours * 60 * 60 * 1000).toISOString();
   ```

6. **Store in Supabase** via supabaseAdmin (service role — bypasses RLS):
   - First, check if an expired entry exists for this url_hash. If so, delete it before inserting (upsert on url_hash).
   - Insert into `menus`: { url, url_hash: urlHash, source_type: sourceType, raw_text: rawText, expires_at: expiresAt }
   - Get back the new menu.id
   - Insert into `menu_items`: map parsed.dishes to rows with menu_id, spread dish fields, add sort_order from array index

7. **Return** the full menu with items (re-query or construct from insert results)

**Exports:** `hashUrl`, `getOrParseMenu`, `getAdminConfig`
  </action>
  <verify>
- `grep 'server-only' lib/cache.ts` confirms server-only guard
- `grep 'hashUrl' lib/cache.ts` confirms hash function exists
- `grep 'getOrParseMenu' lib/cache.ts` confirms orchestrator function exists
- `grep 'supabaseAdmin' lib/cache.ts` confirms service role used for writes
- `grep 'supabase' lib/cache.ts | grep -v 'Admin'` confirms anon client used for reads
- `grep 'parseDishesFromMenu' lib/cache.ts` confirms LLM call on cache miss
- `grep 'expires_at' lib/cache.ts` confirms TTL check in cache query
- `npx tsc --noEmit` passes (no type errors)
  </verify>
  <done>
Cache layer at lib/cache.ts exports hashUrl (SHA-256 with URL normalization), getAdminConfig (reads admin settings with defaults), and getOrParseMenu (cache-aware orchestrator: anon read → LLM on miss → service role write). Phase 5 Scan Pipeline can now call getOrParseMenu(url, sourceType, rawText) and get back a full MenuWithItems.
  </done>
</task>

</tasks>

<verification>
1. `npm ls ai @ai-sdk/openai zod server-only` — all installed, zod at 3.25.76
2. `npx tsc --noEmit` — project compiles with no type errors
3. `grep -r "generateObject" lib/` — returns nothing (deprecated API not used)
4. `grep -r "server-only" lib/openai.ts lib/cache.ts lib/supabase-admin.ts` — all 3 server-only files have the guard
5. `grep -r "NEXT_PUBLIC.*SERVICE_ROLE" lib/` — returns nothing (service role key never public)
6. Code review: getOrParseMenu reads from anon client, writes via supabaseAdmin, calls parseDishesFromMenu only on cache miss
</verification>

<success_criteria>
- parseDishesFromMenu returns Zod-validated { dishes: DishResponse[] } — no raw LLM string output
- getOrParseMenu returns cached result on url_hash match with valid expires_at (no LLM call)
- getOrParseMenu calls LLM and stores result on cache miss
- Admin config (model, TTL) is read from Supabase with sensible defaults
- All server-only modules are guarded with import 'server-only'
- Zod pinned at v3.25.76 (not v4)
</success_criteria>

<output>
After completion, create `.planning/phases/04-infrastructure-foundation/04-02-SUMMARY.md`
</output>
